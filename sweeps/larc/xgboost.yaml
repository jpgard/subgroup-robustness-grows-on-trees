program: scripts/train.py
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - ${args}
  - "--dataset=larc"
  - "--dataset_kwargs={\"subsample_size\": 0.3, \"train_frac\": 0.34}"

name: "xgboost-sweep-cls-larc-v1.0"
description: "hyperparameter sweep for XGBoost."
method: grid
metric:
  name: accuracy_test
  goal: maximize

parameters:

  model_type:
    values: ["xgboost"]

  # all default parameters for XGBoost are documented here:
  # https://xgboost.readthedocs.io/en/stable/parameter.html
  learning_rate:
    values: [ 0.1, 0.3, 1.0, 2.0 ]  # default: 0.3

  #Minimum loss reduction required to make a further partition on a leaf node
  # of the tree. The larger gamma is, the more conservative the algorithm will be.
  # alias for gamma.
  min_split_loss:
   values: [0, 0.1, 0.5] # default: 0

  # Maximum depth of a tree. Increasing this value will make the model more
  # complex and more likely to overfit. 0 indicates no limit on depth.
  # Beware that XGBoost aggressively consumes memory when training a deep tree.
  max_depth:
    values: [4, 6, 8]

  # colsample_bytree is the subsample ratio of columns when constructing each
  # tree. Subsampling occurs once for every tree constructed.
  colsample_bytree:
    values: [0.7, 0.9, 1]  # default: 1

  # colsample_bylevel is the subsample ratio of columns for each level.
  # Subsampling occurs once for every new depth level reached in a tree.
  # Columns are subsampled from the set of columns chosen for the current tree.
  colsample_bylevel:
    values: [0.7, 0.9, 1]  # default: 1

  # colsample_bynode is not supported for GPU.

  # Maximum number of discrete bins to bucket continuous features.
  #
  # Increasing this number improves the optimality of splits at the
  # cost of higher computation time.
  max_bin:
    values: [128, 256, 512] # default: 256

  #Controls a way new nodes are added to the tree.
  #Currently supported only if tree_method is set to hist, approx or gpu_hist.
  #Choices:
  #depthwise: split at nodes closest to the root.
  #lossguide: split at nodes with highest loss change.
  grow_policy:
    values: ["depthwise", "lossguide"]  # default: depthwise